---
layout: post
title:  "Quotes from Thinking in Systems by Donella  H. Meadows"
author: Miniek
categories: [ systems thinking ]
image: assets/images/12.jpg
featured: true
hidden: false
---

## Thinking in Systems by Donella  H. Meadows

### Chapter one: The Basics

> A system is an interconnected set of elements that is coherently organized in a war that achieves something

---

> System must consist of three kinds of things: elements,  interconnections, and a function orpurpose

---

> You think that because you understand "one" that you must therefore understand "two" because one and one make two. But you forget that  you must also understand "and". --Sufi teaching story

---

> How to know you are loking ath the system or just bunch of stuff?
> * Can you identify parts? ... and
> * Do the parts affect each other? ... and
> * Do the parts together produce an effect that is different form effects of each part on its own? ... and perhaps
> * Does the effect,  the behavior over time, persist in a variety of circumstances?

---

> Interconnections, the relationships (...) hold the elements together.

---

> Many of the interconnections in systems operate through the flow of information. Information holds the elements together and plays a great role in determining how they operate.

---

> The best way to deduce the system's purpose is to watch for a while to see how the system behaves.

---

> If a government proclaims its interest in protecting the environment but allocates little money or effort toward  that goal, environment protection is not, in fact, the government's purpose.

> (...) One of the most frustrating aspects of systems is that the purposes of subunits may add up to overall behavior that no one wants.

---

> Systems can be nested within systems.

---

> You can understand the relative importance of a system's elements, interconnections, and purposes by imagining them changed one by one.

---

> Changing elements usually has the least effect on the system.

---

> Changing interconnections in a system can change it dramatically.

---

> (...) The least obvious part of the system, its function or purpose, is often the most crucial determinant of the system's behavior. Interconnections are also critically important. Changing relationships usually changes system behavior. The elements, the parts of the systems we are most likely to notice , are often (not always) least importnat in defining the unique characteristics of the system - *unless changing an element also results in changing relationships or purpose.*

---

> Information contained in nature... allows us a partial reconstruction of the past... The development of the meanders in a river, the increasing complexity of the earth's crust... the information-storing devices in the same manner that genetic systems are... Storing information means increasing the complexity of the mechanism. - Ramon Margalef

---

> Stocks are elements of the system that you can see, feel, count, or measure at any given time.

---

> If you understand the dynamics of stocks and flows - their behavior over time - you understand a good deal about the behavior of complex systems.

---

> Therefore, we sometimes miss seeing that we can fill a bathtub by increasing the inflow rate, but also by decreasing the outflow rate.

---

> The stock takes time to change, because flows take time to flow.

---

> If you have a sense of the rates of change of stock, you don't expect things to happen faster that they can happen.

---

> System thinkers see the world as a collection of stocks along with the mechanisms for regulating the levels in the stocks by manipulating flows.

---

> It is the consistent behavior pattern over a long period of time that is the first hint of the existence of a feedback loop.

---

> A feedback loop is a closed chain of casual connections from a stock, through a set of decisions or rules or physical laws or actions that are dependent on the level of the stock, and back again through a flow to change the stock.

---

> Balancing feedback loops are *goal-seeking* or *stability-seeking*.

---

> A balancing feedback loop opposes whatever direction of change is imposed on a system. If you push a stock too far up, a balancing feedback loop will try to pull it back down. If you push a it too far down, a balancing feedback loop will try to pull it back up. 

---

> Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as constant fraction of itself.

---

> Reinforcing feedback loops are self-enhancing, leading to exponential growth or to runway collapses over time. They are found whenever a stock has the capacity to reinforce itself. 

---

> The time it takes for an exponentially growing stock to double in size, the "doubling time", equals approximately 70 divided by the growth rate (expressed as a percentage).

---

> If A causes B is it possible that B also causes A?

---

> The concept of feedback opens up the idea that a system can cause its own behavior.

---


### Chapter two: A Brief Visit to the Systems Zoo

> The information delivered by a feedback loop can only affect the future behavior; it can't deliver the information, and so can't have an impact fact enough to correct the behavior that drive to current feedback.

---

> (...) There will always be delays in responding.

---

> When one loop dominates another, it has a stronger impact n behavior.

---

> A stock governed by linked reinforcing and balancing loops will grow exponentially if the reinforcing lop dominates the balancing one. It will die off if the balancing loop dominates the reinforcing one. It will level off if the two are equal in strength. Or it will do a sequence of those things, one after another, if the relative strengths of the two loops change over time.

---

> System dynamics models explore possible futures and ask "what if" questions.

---

> Model utility depends not on whether its driving scenarios are realistic (since no one can know that fr sure), but on whether it responds with a realistic pattern of behavior.

---

> Systems with similar feedback structures produce similar dynamic behaviors.

---

> One of the central insights of systems theory, as central as the observation that systems largely cause own behavior, is that systems with similar feedback structures produce similar dynamic behaviors, even if the onward appearance of the systems is completely dissimilar.

---

> A delay in a balancing feedback loop makes a system likely to oscillate.

---

> Delays are pervasive in systems, and they are strong determinants of behavior. Changing the length of a delay may (or may not, depending on the type of delay and the relative lengths of other delays) make a large change in the behavior of a system.

---

> In physical, exponentially growing systems, there must be at least one reinforcing loop driving the growth *and* at least one balancing loop constraining the growth, because no physical system can grow forever in a finite environment.

---

### Chapter three: Why Systems Work So Well

> Systems need to be managed not only for productivity or stability, they also need to be managed for resilience - ability to recover from perturbation, the ability to restore or repair themselves.

---

> Productivity and stability are the usual excuses for turning creative human beings into mechanical adjuncts to production processes.

---

> Self-organization produces heterogeneity and unpredictability. It is likely to come up with a whole new structures, whole new ways of doing things. It requires freedom and experimentation, and a certain amount of disorder. These conditions that encourage self-organization often cab be  scary for individuals and threatening for power structures.

---

> When a subsystem's goals dominate at the expense of the total system's goals, the resulting behavior is called sub-optimization.

---

> Just as damaging as sub-optimization, of course, is the problem of too much central control.

---

> To be highly functional system, hierarchy must balance welfare, freedoms, and responsibilities of the subsystems and total system - there must be enough central control toachieve coordination toward the large-system goal, and enough autonomy to keep all subsystems flourishing, functioning, and self-organizing.

---

> Hierarchical systems evolve from the bottom up. The purpose of the upper layers of hierarchy is to serve the purposes of the lower layers.

---

> (...) Long-term behavior provides clues to the underlying system structure. And structure is key to understanding not just *what* is happening, but *why*. 

---

> System structure  is the source of system behavior System behavior reveals itself as a series of events over time.

---

> System thinking goes back and fourth constantly between structure (diagrams of stocks,flows,and feedback) and behavior (time graphs). System thinkers strive to understand the connections between the hand releasing the Slinky (event) and resulting osculations (behavior) and the mechanical characteristics of Slinky's helical coil (structure).

---

> Flows go up and down, on and off, in all sorts of combinations, in response to stocks, not to other flows.

---

> (...) Behavior based econometric models are pretty good at predicting the near-term performance of the economy, quite bad at predicting the longer-term performance, and terrible at telling one how to improe the performance of the economy. 

---

> The greatest complexities arise exactly at boundaries.

---

> The lesson of boundaries is hard even for system thinkers to get, There is no single, legitimate boundary to draw around the system. We have to invent boundaries for clarity and sanity; and boundaries ca produce problems when we forget that we've artificially created them.

---

> There are no separate systems. The world is a continuum. Where to draw a boundary around the system depends on the purpose of the discussion.

---

> At any given time, the input that is most important to a system is the one that is most limiting.

---

> When there are long delays in feedback loops, some sort of foresight is essential. To act only when a problem becomes obvious is to miss an important opportunity to solve the problem.

---

> Bounded rationality means that people make quite reasonable decisions based on the information they have. But they don't have perfect information, especially about the more distant parts of the system.

---

> We live in an exaggerated present - we pay too much attention to recent experience and too litle to the past, focusing on current events rather than long-term behavior.

--- 

> We don't let in at all news we don't like, or information that doesn't fit our mental models. Which is to say, we don't even make decisions that optimize our own individual good, much less the good of the system as w whole.

---

> Taking out one person from a position of bounded rationality and putting in another person is not likely to make much difference.

---

> Change comes from stepping outside the limited information that can be seen from any single place in the system and getting an overview.

---

> The bounded rationality of each of actor in a system - determined by the information, incentives, disincentives, goals, stresses, and constraints impinging on that actor - may or may not lead to decisions that further welfare of a system as a whole. If they do not, putting the new actors into the same system will not improvesystem's performance. What makes a difference is redesigning the system to improve the information, incentives, disincentives, goals, stresses, and constraints that have on a specific actors.
